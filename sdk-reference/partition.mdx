---
title: 'Partition'
description: 'Documentation for Aryn SDK Partition'
---

Please find the documentation for the Aryn SDK Partition module below.

## convert_image_element

Convert an image element to a more usable format. If no format is specified, create a PIL Image object. If a format is specified, output the bytes of the image in that format. If b64encode is set to True, base64-encode the bytes and return them as a string.

**Parameters:**

- **elem**: Required. An image element from the `elements` field of a `partition_file` response.
- **format**: Optional. A string specifying the format to output bytes to. Default is 'PIL'.
- **b64encode**: Optional. A boolean that when set to True enables base64-encoding of the output bytes of this function. Format cannot be 'PIL' when this option is True.

**Returns:**

Either a PIL Image object, bytes of an image, or a base64-encoded image as a str.

**Example:**

```python
from aryn_sdk.partition import partition_file, convert_image_element

with open("my-favorite-pdf.pdf", "rb") as f:
    data = partition_file(
        f,
        extract_images=True
    )
image_elts = [e for e in data['elements'] if e['type'] == 'Image']

pil_img = convert_image_element(image_elts[0])
jpg_bytes = convert_image_element(image_elts[1], format='JPEG')
png_str = convert_image_element(image_elts[2], format="PNG", b64encode=True)
```


## draw_with_boxes

Create a list of images from the provided PDF, one for each page, with bounding boxes detected by the partitioner drawn on.

**Parameters:**

- **pdf_file**: Required. A BinaryIO (e.g. from a file opened in "b" mode) of a PDF or a path to a PDF file expressed as a str or a PathLike object upon which to draw.
- **partitioning_data**: Required. The output from `aryn_sdk.partition.partition_file`.
- **draw_table_cells**: Optional. A boolean that when True, makes the function draw individually detected cells of tables. When False, the bounding boxes of table cells are not drawn but the outer bounding boxes of tables and the bounding boxes of all other elements are still drawn. Default is False.

**Returns:**

A list of images of pages of the PDF, each with bounding boxes drawn on.

**Example:**

```python
from aryn_sdk.partition import partition_file, draw_with_boxes

with open("my-favorite-pdf.pdf", "rb") as f:
    data = partition_file(
        f,
        aryn_api_key="MY-ARYN-TOKEN",
        use_ocr=True,
        extract_table_structure=True,
        extract_images=True
    )
pages = draw_with_boxes("my-favorite-pdf.pdf", data, draw_table_cells=True)
```
## partition_file

Sends file to Aryn DocParse and returns a dict of its document structure and text.

**Parameters:**

- **file**: pdf file to partition
- **aryn_api_key**: aryn api key, provided as a string
- **aryn_config**: ArynConfig object, used for finding an api key. If aryn_api_key is set it will override this. Default: The default ArynConfig looks in the env var ARYN_API_KEY and the file ~/.aryn/config.yaml
- **threshold**: value to specify the cutoff for detecting bounding boxes. Must be set to "auto" or a floating point value between 0.0 and 1.0. Default: None (APS will choose)
- **use_ocr**: extract text using an OCR model instead of extracting embedded text in PDF. Default: False
- **ocr_images**: attempt to use OCR to generate a text representation of detected images. Default: False
- **extract_table_structure**: extract tables and their structural content. Default: False
- **table_extraction_options**: Specify options for table extraction, currently only supports boolean 'include_additional_text': if table extraction is enabled, attempt to enhance the table structure by merging in tokens from text extraction. This can be useful for tables with missing or misaligned text, and is False by default. Default: {}
- **extract_images**: extract image contents. Default: False
- **selected_pages**: list of individual pages (1-indexed) from the pdf to partition. Default: None
- **aps_url**: url of the Aryn Partitioning Service endpoint. Default: "https://api.aryn.cloud/v1/document/partition"
- **ssl_verify**: verify ssl certificates. In databricks, set this to False to fix ssl incompatibilities.
- `chunking_options`: A tree of options for specifying chunking behavior. Chunking is only performed when this option is present, and the default options are chosen when chunking_options is specified as just `{}`. The full options are available in the [OpenAPI spec](../api-reference/endpoint/partition).
    - `merging_strategy`: A string specifying the strategy to use to combine and split chunks. Valid values are 'header_augmenter', 'greedy_text_element', and 'marked'. The default and recommended merger is 'header_augmenter'.
        - Behavior of `header_augmenter`:
        Combines adjacent `Section-header` and `Title` elements into a new `Section-header` element. Merges elements into a chunk with its most recent `Section-header`. If the chunk would contain too many tokens, then it starts a new chunk copying the Section-header to the start of this new chunk and continues. Merges elements on different pages, unless `merge_across_pages` is set to `False`.
        - Behavior of `marked` merger:
        For each page, it detects whether the elements are present in two columns and if so, it orders them properly with the left column appearing in the order first. Then, it drops elements that are only one token in size. It also drops elements in the top and bottom 5% of the page. Elements returned do not have a `type`. The `marked` merger always breaks across pages.
        - Behavior of `greedy_text_element` merger:
        Merges elements into the last most recently merged set of elements unless doing so would make its token count exceed `max_tokens`. In that case, it would keep the new element separate and start merging subsequent elements into that one, following the same rule. Merges elements on different pages, unless `merge_across_pages` is set to `False`.
    - `max_tokens`: An integer specifying cutoff for splitting chunks that are too large. Default value is 512.
    - `tokenizer`: A string specifying the tokenizer to use when determining how characters in a chunk are grouped. Valid values are 'openai_tokenizer', 'character_tokenizer', and 'huggingface_tokenizer'. Defaults to openai_tokenizer.
    - `tokenizer_options`: A tree specifying the options for the chosen tokenizer. Defaults to 'model_name': 'text-embedding-3-small', which works with the OpenAI tokenizer.
        - Available options for `openai_tokenizer`:
            - `model_name`: Accepts all models supported by OpenAI's [tiktoken tokenizer](https://github.com/openai/tiktoken). Default is "text-embedding-3-small"
        - Available options for `HuggingFaceTokenizer`:
            - `model_name`: Accepts all huggingface tokenizers from the [huggingface/tokenizers repo](https://github.com/huggingface/tokenizers)
        - `character_tokenizer` does not take any options.
    - `merge_across_pages`: A boolean that determines whether the chunker should attempt to merge chunks on different pages. Defaults to `True`. Does not apply to the 'marked' merger, which never merges across pages.
- **output_format**: controls output representation; can be set to markdown. Default: None (JSON elements)

**Returns:**

A dictionary containing "status" and "elements". If output_format is markdown, dictionary of "status" and "markdown".

**Example:**

```python
from aryn_sdk.partition import partition_file

with open("my-favorite-pdf.pdf", "rb") as f:
    data = partition_file(
        f,
        aryn_api_key="MY-ARYN-TOKEN",
        use_ocr=True,
        extract_table_structure=True,
        extract_images=True
    )
elements = data['elements']
```

## table_elem_to_dataframe

Create a pandas DataFrame representing the tabular data inside the provided table element. If the element is not of type 'table' or doesn't contain any table data, return None instead.

**Parameters:**

- **elem**: An element from the 'elements' field of a `partition_file` response.

**Example:**

```python
from aryn_sdk.partition import partition_file, table_elem_to_dataframe

with open("partition-me.pdf", "rb") as f:
    data = partition_file(
        f,
        use_ocr=True,
        extract_table_structure=True,
        extract_images=True
    )

# Find the first table and convert it to a dataframe
df = None
for element in data['elements']:
    if element['type'] == 'table':
        df = table_elem_to_dataframe(element)
        break
```


## tables_to_pandas

For every table element in the provided partitioning response, create a pandas DataFrame representing the tabular data. Return a list containing all the elements, with tables paired with their corresponding DataFrames.

**Parameters:**

- **data**: a response from `partition_file`

**Example:**

```python
from aryn_sdk.partition import partition_file, tables_to_pandas

with open("my-favorite-pdf.pdf", "rb") as f:
    data = partition_file(
        f,
        aryn_api_key="MY-ARYN-TOKEN",
        use_ocr=True,
        extract_table_structure=True,
        extract_images=True
    )
elts_and_dataframes = tables_to_pandas(data)
```
